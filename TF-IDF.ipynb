{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Modules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\QYH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\QYH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\QYH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\QYH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\QYH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\QYH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\QYH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\QYH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from modules import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Loading Data ************\n",
      "\n",
      "\n",
      "Summary of data\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         25000 non-null  object\n",
      " 1   sentiment  25000 non-null  int64 \n",
      " 2   review     25000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.1+ KB\n",
      "No of Rows: 25000\n",
      "No of Columns: 3\n",
      "\n",
      "Data View: Last 3 Instances\n",
      "\n",
      "              id  sentiment                                             review\n",
      "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
      "24998  \"10194_3\"          0  \"This 30 minute documentary BuÃ±uel made in the...\n",
      "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h...\n",
      "\n",
      "Class Counts(label, row): Total\n",
      "1    12500\n",
      "0    12500\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Data View: First 5 Instances\n",
      "\n",
      "         id  sentiment                                             review\n",
      "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
      "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
      "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
      "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
      "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n",
      "No of Rows(After removing duplicates): 25000\n"
     ]
    }
   ],
   "source": [
    "X,y=load_data('./data/labeledTrainData.tsv',colname=['review','sentiment'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Spliting Data **************\n",
      "\n",
      "\n",
      "************** Data After Splitting **************\n",
      "\n",
      "Train Data: (20000, 1)\n",
      "Test Data: (5000, 1)\n",
      "\n",
      "Class Counts(label, row): Train\n",
      "1    10018\n",
      "0     9982\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Test\n",
      "0    2518\n",
      "1    2482\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "First 5 Instance: Train\n",
      "                                                  review\n",
      "6167   \"Some unsuspecting films carry a message that ...\n",
      "3101   \"Even the first 10 minutes of this movie were ...\n",
      "17307  \"To me this was more a wake up call, and reali...\n",
      "3950   \"Shower keeps within itself in so many ways. A...\n",
      "893    \"Brian Yuzna is often frowned upon as a direct...\n",
      "\n",
      "First 5 Instance: Test\n",
      "                                                  review\n",
      "7799   \"\\\"Girlfight\\\" is much more of a coming-of-age...\n",
      "4427   \"This movie will go down down in history as on...\n",
      "14941  \"I have to agree with Cal-37 it's a great movi...\n",
      "11644  \"Most of the Atomic Age monster movies I saw o...\n",
      "15548  \"I saw this film at the Adelaide Film Festival...\n",
      "\n",
      "************** Resetting Index **************\n",
      "\n",
      "\n",
      "************** Data After Resetting **************\n",
      "\n",
      "\n",
      "First 5 Instance: Train\n",
      "\n",
      "                                              review\n",
      "0  \"Some unsuspecting films carry a message that ...\n",
      "1  \"Even the first 10 minutes of this movie were ...\n",
      "2  \"To me this was more a wake up call, and reali...\n",
      "3  \"Shower keeps within itself in so many ways. A...\n",
      "4  \"Brian Yuzna is often frowned upon as a direct...\n",
      "\n",
      "First 5 Instance: Test\n",
      "\n",
      "                                              review\n",
      "0  \"\\\"Girlfight\\\" is much more of a coming-of-age...\n",
      "1  \"This movie will go down down in history as on...\n",
      "2  \"I have to agree with Cal-37 it's a great movi...\n",
      "3  \"Most of the Atomic Age monster movies I saw o...\n",
      "4  \"I saw this film at the Adelaide Film Festival...\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train,  y_test=split_data(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train=X_train.iloc[:, -1].apply(preprocess_data)\n",
    "\n",
    "# word list --> str\n",
    "X_train = X_train.apply(lambda x: \" \".join(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_test=X_test.iloc[:, -1].apply(preprocess_data)\n",
    "\n",
    "# word list --> str\n",
    "X_test = X_test.apply(lambda x: \" \".join(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get TF-IDF vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF over\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n",
    "tfidf = TFIDF(min_df=2, max_features=None, strip_accents='unicode',analyzer='word',token_pattern=r'\\w{1,}', ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1)\n",
    "\n",
    "data_all = X_train.tolist()+X_test.tolist()\n",
    "len_train = len(X_train)\n",
    "tfidf.fit(data_all)\n",
    "data_all = tfidf.transform(data_all)\n",
    "# Revert to training set and test set parts\n",
    "X_train = data_all[:len_train]\n",
    "X_test = data_all[len_train:]\n",
    "print('TF-IDF over')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "MultinomialNB()"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Naive Bayesian training ###\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "model_NB = MNB()\n",
    "model_NB.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.885\n",
      "recall: 0.8944399677679291\n",
      "precision: 0.8764311093564943\n",
      "f1: 0.8853439680957129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "# fit\n",
    "y_predict = model_NB.predict(X_test)\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# evaluate\n",
    "accuracy = accuracy_score(y_test_np, y_predict)\n",
    "print(f\"accuracy: {accuracy}\")\n",
    "\n",
    "recall = recall_score(y_test_np, y_predict)\n",
    "print(f\"recall: {recall}\")\n",
    "\n",
    "precision = precision_score(y_test_np, y_predict)\n",
    "print(f\"precision: {precision}\")\n",
    "\n",
    "f1 = f1_score(y_test_np, y_predict)\n",
    "print(f\"f1: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 fold cross validation score of Bayes classifier: 0.88504\n"
     ]
    }
   ],
   "source": [
    "# To get a more accurate performance evaluation,\n",
    "# use cross-validation to fit and evaluate evaluate the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model_NB = MNB()\n",
    "scores = cross_val_score(model_NB, data_all, y_train.tolist()+y_test.tolist(), cv=10)\n",
    "print(\"10 fold cross validation score of Bayes classifier:\", np.mean(scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_LR = LogisticRegression()\n",
    "model_LR.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.885\n",
      "recall: 0.9016921837228042\n",
      "precision: 0.8711560918645387\n",
      "f1: 0.8861611562066918\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "y_predict = model_LR.predict(X_test)\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# evaluate\n",
    "accuracy = accuracy_score(y_test_np, y_predict)\n",
    "print(f\"accuracy: {accuracy}\")\n",
    "\n",
    "recall = recall_score(y_test_np, y_predict)\n",
    "print(f\"recall: {recall}\")\n",
    "\n",
    "precision = precision_score(y_test_np, y_predict)\n",
    "print(f\"precision: {precision}\")\n",
    "\n",
    "f1 = f1_score(y_test_np, y_predict)\n",
    "print(f\"f1: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 fold cross validation score of LogisticRegression: 0.8877200000000001\n"
     ]
    }
   ],
   "source": [
    "# To get a more accurate performance evaluation,\n",
    "# use cross-validation to fit and evaluate evaluate the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_model_LR = LogisticRegression()\n",
    "scores = cross_val_score(cross_val_model_LR, data_all, y_train.tolist()+y_test.tolist(), cv=10)\n",
    "print(\"10 fold cross validation score of LogisticRegression:\", np.mean(scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#test\n",
    "test_data=pd.read_csv(\"data/testData.tsv\",sep = \"\\t\")\n",
    "X_test=test_data['review'].apply(preprocess_data)\n",
    "\n",
    "# word list --> str\n",
    "X_test = X_test.apply(lambda x: \" \".join(x))\n",
    "\n",
    "X_test = tfidf.transform(X_test)\n",
    "test_predicted = np.array(model_LR.predict(X_test))\n",
    "lr_output = pd.DataFrame(data=test_predicted, columns=['sentiment'])\n",
    "lr_output['id'] = test_data['id']\n",
    "lr_output = lr_output[['id', 'sentiment']]\n",
    "lr_output.to_csv('tf-idf.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}