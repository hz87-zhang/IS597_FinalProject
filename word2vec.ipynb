{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Modules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from modules import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Loading Data ************\n",
      "\n",
      "\n",
      "Summary of data\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         25000 non-null  object\n",
      " 1   sentiment  25000 non-null  int64 \n",
      " 2   review     25000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.1+ KB\n",
      "No of Rows: 25000\n",
      "No of Columns: 3\n",
      "\n",
      "Data View: Last 3 Instances\n",
      "\n",
      "              id  sentiment                                             review\n",
      "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
      "24998  \"10194_3\"          0  \"This 30 minute documentary Buñuel made in the...\n",
      "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h...\n",
      "\n",
      "Class Counts(label, row): Total\n",
      "1    12500\n",
      "0    12500\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Data View: First 5 Instances\n",
      "\n",
      "         id  sentiment                                             review\n",
      "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
      "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
      "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
      "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
      "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n",
      "No of Rows(After removing duplicates): 25000\n"
     ]
    }
   ],
   "source": [
    "X,y=load_data('./data/labeledTrainData.tsv',colname=['review','sentiment'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "266756\n"
     ]
    }
   ],
   "source": [
    "## get the list of sentences\n",
    "def review_to_sentences(review, tokenizer):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(raw_sentence)\n",
    "    return sentences\n",
    "\n",
    "sentences = []\n",
    "\n",
    "# A tokenizer for dividing sentences\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "for review in X['review']:\n",
    "    sentences+=review_to_sentences(review, tokenizer)\n",
    "print(len(X))\n",
    "print(len(sentences))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#preprocess\n",
    "sentences = list(map(preprocess_data, sentences))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## word2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train word2vec...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "print(\"train word2vec...\")\n",
    "model = Word2Vec(sentences, size=250, window=5, min_count=5, workers=12, iter=10, sg=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#save model\n",
    "model_name = \"./model/word2vec_train_data.model\"\n",
    "model.save(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the vector of X_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#get review vector\n",
    "def get_review_vector(review):\n",
    "    global word_vec\n",
    "    word_vec = np.zeros((1,250))\n",
    "    for word in review:\n",
    "        if word in model:\n",
    "            word_vec = np.concatenate((word_vec, np.array([model[word]])), axis=0)\n",
    "    return pd.Series(word_vec.mean(axis = 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Spliting Data **************\n",
      "\n",
      "\n",
      "************** Data After Splitting **************\n",
      "\n",
      "Train Data: (20000, 1)\n",
      "Test Data: (5000, 1)\n",
      "\n",
      "Class Counts(label, row): Train\n",
      "1    10018\n",
      "0     9982\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Test\n",
      "0    2518\n",
      "1    2482\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "First 5 Instance: Train\n",
      "                                                  review\n",
      "6167   \"Some unsuspecting films carry a message that ...\n",
      "3101   \"Even the first 10 minutes of this movie were ...\n",
      "17307  \"To me this was more a wake up call, and reali...\n",
      "3950   \"Shower keeps within itself in so many ways. A...\n",
      "893    \"Brian Yuzna is often frowned upon as a direct...\n",
      "\n",
      "First 5 Instance: Test\n",
      "                                                  review\n",
      "7799   \"\\\"Girlfight\\\" is much more of a coming-of-age...\n",
      "4427   \"This movie will go down down in history as on...\n",
      "14941  \"I have to agree with Cal-37 it's a great movi...\n",
      "11644  \"Most of the Atomic Age monster movies I saw o...\n",
      "15548  \"I saw this film at the Adelaide Film Festival...\n",
      "\n",
      "************** Resetting Index **************\n",
      "\n",
      "\n",
      "************** Data After Resetting **************\n",
      "\n",
      "\n",
      "First 5 Instance: Train\n",
      "\n",
      "                                              review\n",
      "0  \"Some unsuspecting films carry a message that ...\n",
      "1  \"Even the first 10 minutes of this movie were ...\n",
      "2  \"To me this was more a wake up call, and reali...\n",
      "3  \"Shower keeps within itself in so many ways. A...\n",
      "4  \"Brian Yuzna is often frowned upon as a direct...\n",
      "\n",
      "First 5 Instance: Test\n",
      "\n",
      "                                              review\n",
      "0  \"\\\"Girlfight\\\" is much more of a coming-of-age...\n",
      "1  \"This movie will go down down in history as on...\n",
      "2  \"I have to agree with Cal-37 it's a great movi...\n",
      "3  \"Most of the Atomic Age monster movies I saw o...\n",
      "4  \"I saw this film at the Adelaide Film Festival...\n"
     ]
    }
   ],
   "source": [
    "#preprocess\n",
    "X_train, X_test, y_train,  y_test=split_data(X,y)\n",
    "X_train=X_train.iloc[:, -1].apply(preprocess_data)\n",
    "X_test=X_test.iloc[:, -1].apply(preprocess_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "        0         1         2         3         4         5         6    \\\n0  0.040529 -0.056504 -0.119637  0.049388 -0.017562 -0.020660  0.039044   \n1  0.048778 -0.062611 -0.047675  0.070007  0.034960  0.010693 -0.035031   \n2  0.081458 -0.125897 -0.092605  0.073621  0.072933  0.002953 -0.006336   \n3  0.007783 -0.081884 -0.039946  0.030894  0.009550  0.052569 -0.003978   \n4  0.038180 -0.094914 -0.058401 -0.015450  0.041275  0.006204 -0.001451   \n\n        7         8         9    ...       240       241       242       243  \\\n0  0.108896 -0.036914 -0.084274  ...  0.018443  0.014037 -0.030989 -0.009136   \n1  0.158397 -0.153992 -0.039895  ... -0.012425 -0.070851  0.006201 -0.001099   \n2  0.218053 -0.130141 -0.061667  ...  0.029945 -0.053330 -0.002620  0.042959   \n3  0.048011 -0.075120 -0.066794  ... -0.026188 -0.103521  0.000062  0.019256   \n4  0.169006 -0.066129 -0.105810  ... -0.010240 -0.040620  0.053438 -0.003202   \n\n        244       245       246       247       248       249  \n0 -0.069813  0.069940  0.147117 -0.065478  0.146323 -0.083354  \n1 -0.078519  0.135354  0.141956 -0.037876  0.196699  0.003221  \n2 -0.082090  0.137970  0.187883 -0.016886  0.167745 -0.046418  \n3 -0.087347  0.117627  0.089923 -0.041807  0.135751 -0.038079  \n4 -0.072592  0.123155  0.151914  0.000943  0.249972 -0.037866  \n\n[5 rows x 250 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>240</th>\n      <th>241</th>\n      <th>242</th>\n      <th>243</th>\n      <th>244</th>\n      <th>245</th>\n      <th>246</th>\n      <th>247</th>\n      <th>248</th>\n      <th>249</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.040529</td>\n      <td>-0.056504</td>\n      <td>-0.119637</td>\n      <td>0.049388</td>\n      <td>-0.017562</td>\n      <td>-0.020660</td>\n      <td>0.039044</td>\n      <td>0.108896</td>\n      <td>-0.036914</td>\n      <td>-0.084274</td>\n      <td>...</td>\n      <td>0.018443</td>\n      <td>0.014037</td>\n      <td>-0.030989</td>\n      <td>-0.009136</td>\n      <td>-0.069813</td>\n      <td>0.069940</td>\n      <td>0.147117</td>\n      <td>-0.065478</td>\n      <td>0.146323</td>\n      <td>-0.083354</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.048778</td>\n      <td>-0.062611</td>\n      <td>-0.047675</td>\n      <td>0.070007</td>\n      <td>0.034960</td>\n      <td>0.010693</td>\n      <td>-0.035031</td>\n      <td>0.158397</td>\n      <td>-0.153992</td>\n      <td>-0.039895</td>\n      <td>...</td>\n      <td>-0.012425</td>\n      <td>-0.070851</td>\n      <td>0.006201</td>\n      <td>-0.001099</td>\n      <td>-0.078519</td>\n      <td>0.135354</td>\n      <td>0.141956</td>\n      <td>-0.037876</td>\n      <td>0.196699</td>\n      <td>0.003221</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.081458</td>\n      <td>-0.125897</td>\n      <td>-0.092605</td>\n      <td>0.073621</td>\n      <td>0.072933</td>\n      <td>0.002953</td>\n      <td>-0.006336</td>\n      <td>0.218053</td>\n      <td>-0.130141</td>\n      <td>-0.061667</td>\n      <td>...</td>\n      <td>0.029945</td>\n      <td>-0.053330</td>\n      <td>-0.002620</td>\n      <td>0.042959</td>\n      <td>-0.082090</td>\n      <td>0.137970</td>\n      <td>0.187883</td>\n      <td>-0.016886</td>\n      <td>0.167745</td>\n      <td>-0.046418</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.007783</td>\n      <td>-0.081884</td>\n      <td>-0.039946</td>\n      <td>0.030894</td>\n      <td>0.009550</td>\n      <td>0.052569</td>\n      <td>-0.003978</td>\n      <td>0.048011</td>\n      <td>-0.075120</td>\n      <td>-0.066794</td>\n      <td>...</td>\n      <td>-0.026188</td>\n      <td>-0.103521</td>\n      <td>0.000062</td>\n      <td>0.019256</td>\n      <td>-0.087347</td>\n      <td>0.117627</td>\n      <td>0.089923</td>\n      <td>-0.041807</td>\n      <td>0.135751</td>\n      <td>-0.038079</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.038180</td>\n      <td>-0.094914</td>\n      <td>-0.058401</td>\n      <td>-0.015450</td>\n      <td>0.041275</td>\n      <td>0.006204</td>\n      <td>-0.001451</td>\n      <td>0.169006</td>\n      <td>-0.066129</td>\n      <td>-0.105810</td>\n      <td>...</td>\n      <td>-0.010240</td>\n      <td>-0.040620</td>\n      <td>0.053438</td>\n      <td>-0.003202</td>\n      <td>-0.072592</td>\n      <td>0.123155</td>\n      <td>0.151914</td>\n      <td>0.000943</td>\n      <td>0.249972</td>\n      <td>-0.037866</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 250 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features = X_train.apply(get_review_vector)\n",
    "X_train_features.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X_test_features = X_test.apply(get_review_vector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8648\n",
      "recall: 0.8678485092667204\n",
      "precision: 0.8609112709832134\n",
      "f1: 0.8643659711075442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "# fit\n",
    "LR_model = LogisticRegression()\n",
    "LR_model = LR_model.fit(X_train_features, y_train)\n",
    "y_predict = LR_model.predict(X_test_features)\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# evaluate\n",
    "accuracy = accuracy_score(y_test_np, y_predict)\n",
    "print(f\"accuracy: {accuracy}\")\n",
    "\n",
    "recall = recall_score(y_test_np, y_predict)\n",
    "print(f\"recall: {recall}\")\n",
    "\n",
    "precision = precision_score(y_test_np, y_predict)\n",
    "print(f\"precision: {precision}\")\n",
    "\n",
    "f1 = f1_score(y_test_np, y_predict)\n",
    "print(f\"f1: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 fold cross validation score of LogisticRegression: 0.8684000000000001\n"
     ]
    }
   ],
   "source": [
    "# use cross-validation to fit and evaluate evaluate the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_model_LR = LogisticRegression()\n",
    "scores = cross_val_score(cross_val_model_LR, pd.concat([X_train_features, X_test_features], axis=0), y_train.tolist()+y_test.tolist(), cv=10)\n",
    "print(\"10 fold cross validation score of LogisticRegression:\", np.mean(scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "## test\n",
    "test_data=pd.read_csv(\"data/testData.tsv\",sep = \"\\t\")\n",
    "X_test=test_data['review'].apply(preprocess_data)\n",
    "X_test_features = X_test.apply(get_review_vector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "test_predicted = np.array(LR_model.predict(X_test_features))\n",
    "\n",
    "lr_output = pd.DataFrame(data=test_predicted, columns=['sentiment'])\n",
    "lr_output['id'] = test_data['id']\n",
    "lr_output = lr_output[['id', 'sentiment']]\n",
    "lr_output.to_csv('out/word2vec.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}